{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG3c-0XtTpy3"
      },
      "source": [
        "## Синтаксический анализ повести Бориса Васильева - В списках не значился"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VTAxmwsiTaPo"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.language import Doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL1aSsKWS2c3",
        "outputId": "acceba18-08b1-4b50-c3c9-a701c4cc0988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ru-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.8.0/ru_core_news_sm-3.8.0-py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pymorphy3>=1.0.0 in ./.venv/lib/python3.12/site-packages (from ru-core-news-sm==3.8.0) (2.0.6)\n",
            "Requirement already satisfied: dawg2-python>=0.8.0 in ./.venv/lib/python3.12/site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.8.0) (0.9.0)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in ./.venv/lib/python3.12/site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.8.0) (2.4.417150.4580142)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in ./.venv/lib/python3.12/site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.8.0) (80.9.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python -m spacy download ru_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Z4gKS8y8UA9Y"
      },
      "outputs": [],
      "source": [
        "def load_book(*, path: str) -> str:\n",
        "  with open(file=path, mode=\"r\", encoding=\"utf8\") as file:\n",
        "    try:\n",
        "      return file.read()\n",
        "    except:\n",
        "      raise Exception(\"Ошибка открытия файла\")\n",
        "\n",
        "def clean_text(*, text: str) -> str:\n",
        "  return text.lower().replace(\"\\n\", \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Сравнить объем текста до очистки текста от стоп-слов и после. В процентном соотношении"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vw_DxKVhaw_n"
      },
      "outputs": [],
      "source": [
        "def count_not_stop_tokens(*, doc: Doc) -> int:\n",
        "  non_stop_tokens = [token.text for token in doc if not token.is_stop]\n",
        "  \n",
        "  return len(non_stop_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def count_relations_in_percents(*, x: int, y: int) -> int:\n",
        "  return round(x / y * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "nfxjrl_tTpJo",
        "outputId": "14c3bc63-81ed-42b2-dd4f-1a8a3f3d8a9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Процентное соотношение после чистки стоп-слов = 68%\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.load(\"ru_core_news_sm\")\n",
        "\n",
        "PATH_TO_BOOK = \"./book.txt\"\n",
        "\n",
        "book_text = load_book(path=PATH_TO_BOOK)\n",
        "cleaned_text = clean_text(text=book_text)\n",
        "\n",
        "doc = nlp(cleaned_text)\n",
        "\n",
        "non_stop_tokens = count_not_stop_tokens(doc=doc)\n",
        "\n",
        "percents = count_relations_in_percents(x=non_stop_tokens, y=len(doc))\n",
        "\n",
        "print(f\"Процентное соотношение после чистки стоп-слов = {percents}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Произвести синтаксический анализ предложений и определить наиболее часто используемое в качестве корня предложения слово"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('сказать', 24)\n"
          ]
        }
      ],
      "source": [
        "def count_root_words_in_text(*, doc: Doc) -> dict[str, int]:\n",
        "  root_words_counter: dict[str, int] = {}\n",
        "  for sent in doc.sents:\n",
        "    root_token = sent.root\n",
        "    root_lemma = root_token.lemma_\n",
        "    \n",
        "    root_words_counter[root_lemma] = root_words_counter.get(root_lemma, 0) + 1\n",
        "    \n",
        "  return root_words_counter\n",
        "\n",
        "def find_max_value_in_dict(*, dict_to_find: dict[str, int]) -> tuple[str, int]:\n",
        "  max_key = \"\"\n",
        "  \n",
        "  for key, _ in dict_to_find.items():\n",
        "    max_key = key if dict_to_find[key] > dict_to_find.get(max_key, 0) else max_key\n",
        "    \n",
        "  return (max_key, dict_to_find[max_key])\n",
        "\n",
        "\n",
        "root_words_count_dict = count_root_words_in_text(doc=doc)\n",
        "\n",
        "max_count_tuple = find_max_value_in_dict(dict_to_find=root_words_count_dict)\n",
        "\n",
        "print(max_count_tuple)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tokens-homework",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
